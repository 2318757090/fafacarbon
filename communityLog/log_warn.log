2021-03-16 01:01:52,062 WARN [HikariPool-1 housekeeper] c.z.h.p.HikariPool [HikariPool.java:787] HikariPool-1 - Thread starvation or clock leap detected (housekeeper delta=1h33m41s354ms).
2021-03-16 01:01:52,648 WARN [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator [ConsumerCoordinator.java:1027] [Consumer clientId=consumer-test-consumer-group-1, groupId=test-consumer-group] Asynchronous auto-commit of offsets {delete-0=OffsetAndMetadata{offset=1, leaderEpoch=0, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2021-03-16 01:01:52,649 WARN [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator [ConsumerCoordinator.java:1027] [Consumer clientId=consumer-test-consumer-group-2, groupId=test-consumer-group] Asynchronous auto-commit of offsets {comment-0=OffsetAndMetadata{offset=3, leaderEpoch=0, metadata=''}, like-0=OffsetAndMetadata{offset=4, leaderEpoch=0, metadata=''}, follow-0=OffsetAndMetadata{offset=0, leaderEpoch=null, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2021-03-16 01:01:52,648 WARN [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator [ConsumerCoordinator.java:1027] [Consumer clientId=consumer-test-consumer-group-3, groupId=test-consumer-group] Asynchronous auto-commit of offsets {publish-0=OffsetAndMetadata{offset=20, leaderEpoch=0, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2021-03-16 01:01:52,683 WARN [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator [ConsumerCoordinator.java:1048] [Consumer clientId=consumer-test-consumer-group-2, groupId=test-consumer-group] Synchronous auto-commit of offsets {comment-0=OffsetAndMetadata{offset=3, leaderEpoch=0, metadata=''}, like-0=OffsetAndMetadata{offset=4, leaderEpoch=0, metadata=''}, follow-0=OffsetAndMetadata{offset=0, leaderEpoch=null, metadata=''}} failed: Offset commit cannot be completed since the consumer is not part of an active group for auto partition assignment; it is likely that the consumer was kicked out of the group.
2021-03-16 01:01:52,683 WARN [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator [ConsumerCoordinator.java:1048] [Consumer clientId=consumer-test-consumer-group-3, groupId=test-consumer-group] Synchronous auto-commit of offsets {publish-0=OffsetAndMetadata{offset=20, leaderEpoch=0, metadata=''}} failed: Offset commit cannot be completed since the consumer is not part of an active group for auto partition assignment; it is likely that the consumer was kicked out of the group.
2021-03-16 01:01:52,683 WARN [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator [ConsumerCoordinator.java:1048] [Consumer clientId=consumer-test-consumer-group-1, groupId=test-consumer-group] Synchronous auto-commit of offsets {delete-0=OffsetAndMetadata{offset=1, leaderEpoch=0, metadata=''}} failed: Offset commit cannot be completed since the consumer is not part of an active group for auto partition assignment; it is likely that the consumer was kicked out of the group.
2021-03-16 01:28:49,444 WARN [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator [ConsumerCoordinator.java:1027] [Consumer clientId=consumer-test-consumer-group-3, groupId=test-consumer-group] Asynchronous auto-commit of offsets {publish-0=OffsetAndMetadata{offset=20, leaderEpoch=0, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2021-03-16 01:28:49,446 WARN [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator [ConsumerCoordinator.java:1048] [Consumer clientId=consumer-test-consumer-group-3, groupId=test-consumer-group] Synchronous auto-commit of offsets {publish-0=OffsetAndMetadata{offset=20, leaderEpoch=0, metadata=''}} failed: Offset commit cannot be completed since the consumer is not part of an active group for auto partition assignment; it is likely that the consumer was kicked out of the group.
2021-03-16 01:28:49,447 WARN [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator [ConsumerCoordinator.java:1048] [Consumer clientId=consumer-test-consumer-group-1, groupId=test-consumer-group] Synchronous auto-commit of offsets {delete-0=OffsetAndMetadata{offset=1, leaderEpoch=0, metadata=''}} failed: Offset commit cannot be completed since the consumer is not part of an active group for auto partition assignment; it is likely that the consumer was kicked out of the group.
2021-03-16 01:28:49,451 WARN [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator [ConsumerCoordinator.java:1048] [Consumer clientId=consumer-test-consumer-group-2, groupId=test-consumer-group] Synchronous auto-commit of offsets {comment-0=OffsetAndMetadata{offset=3, leaderEpoch=0, metadata=''}, like-0=OffsetAndMetadata{offset=4, leaderEpoch=0, metadata=''}, follow-0=OffsetAndMetadata{offset=0, leaderEpoch=null, metadata=''}} failed: Offset commit cannot be completed since the consumer is not part of an active group for auto partition assignment; it is likely that the consumer was kicked out of the group.
2021-03-16 01:28:49,456 WARN [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator [ConsumerCoordinator.java:1027] [Consumer clientId=consumer-test-consumer-group-1, groupId=test-consumer-group] Asynchronous auto-commit of offsets {delete-0=OffsetAndMetadata{offset=1, leaderEpoch=0, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2021-03-16 01:28:49,460 WARN [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator [ConsumerCoordinator.java:1027] [Consumer clientId=consumer-test-consumer-group-2, groupId=test-consumer-group] Asynchronous auto-commit of offsets {comment-0=OffsetAndMetadata{offset=3, leaderEpoch=0, metadata=''}, like-0=OffsetAndMetadata{offset=4, leaderEpoch=0, metadata=''}, follow-0=OffsetAndMetadata{offset=0, leaderEpoch=null, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2021-03-16 01:28:52,271 WARN [HikariPool-1 housekeeper] c.z.h.p.HikariPool [HikariPool.java:787] HikariPool-1 - Thread starvation or clock leap detected (housekeeper delta=27m239ms).
2021-03-16 10:00:07,450 WARN [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator [ConsumerCoordinator.java:1027] [Consumer clientId=consumer-test-consumer-group-1, groupId=test-consumer-group] Asynchronous auto-commit of offsets {delete-0=OffsetAndMetadata{offset=1, leaderEpoch=0, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2021-03-16 10:00:07,450 WARN [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator [ConsumerCoordinator.java:1048] [Consumer clientId=consumer-test-consumer-group-1, groupId=test-consumer-group] Synchronous auto-commit of offsets {delete-0=OffsetAndMetadata{offset=1, leaderEpoch=0, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2021-03-16 10:00:07,449 WARN [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator [ConsumerCoordinator.java:1027] [Consumer clientId=consumer-test-consumer-group-3, groupId=test-consumer-group] Asynchronous auto-commit of offsets {publish-0=OffsetAndMetadata{offset=20, leaderEpoch=0, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2021-03-16 10:00:07,460 WARN [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator [ConsumerCoordinator.java:1048] [Consumer clientId=consumer-test-consumer-group-3, groupId=test-consumer-group] Synchronous auto-commit of offsets {publish-0=OffsetAndMetadata{offset=20, leaderEpoch=0, metadata=''}} failed: Offset commit cannot be completed since the consumer is not part of an active group for auto partition assignment; it is likely that the consumer was kicked out of the group.
2021-03-16 10:00:19,252 WARN [HikariPool-1 housekeeper] c.z.h.p.HikariPool [HikariPool.java:787] HikariPool-1 - Thread starvation or clock leap detected (housekeeper delta=8h31m26s980ms).
2021-03-16 11:05:42,877 WARN [HikariPool-1 housekeeper] c.z.h.p.HikariPool [HikariPool.java:787] HikariPool-1 - Thread starvation or clock leap detected (housekeeper delta=1h5m23s627ms).
2021-03-16 11:08:02,817 WARN [HikariPool-1 housekeeper] c.z.h.p.HikariPool [HikariPool.java:787] HikariPool-1 - Thread starvation or clock leap detected (housekeeper delta=2m19s940ms).
2021-03-16 11:13:36,330 WARN [HikariPool-1 housekeeper] c.z.h.p.HikariPool [HikariPool.java:787] HikariPool-1 - Thread starvation or clock leap detected (housekeeper delta=5m3s503ms).
2021-03-16 12:32:37,123 WARN [HikariPool-1 housekeeper] c.z.h.p.HikariPool [HikariPool.java:779] HikariPool-1 - Retrograde clock change detected (housekeeper delta=29s809ms), soft-evicting connections from pool.
2021-03-16 12:44:28,848 WARN [HikariPool-1 housekeeper] c.z.h.p.HikariPool [HikariPool.java:787] HikariPool-1 - Thread starvation or clock leap detected (housekeeper delta=11m51s725ms).
2021-03-16 12:54:24,125 WARN [HikariPool-1 housekeeper] c.z.h.p.HikariPool [HikariPool.java:787] HikariPool-1 - Thread starvation or clock leap detected (housekeeper delta=7m55s261ms).
2021-03-16 12:57:24,121 WARN [HikariPool-1 housekeeper] c.z.h.p.HikariPool [HikariPool.java:779] HikariPool-1 - Retrograde clock change detected (housekeeper delta=28s347ms), soft-evicting connections from pool.
